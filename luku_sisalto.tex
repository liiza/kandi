% --------------------------------------------------------------------

\section{Johdanto}



\subsection{Johdantoluku}

Tämä kandinaatintyö käsittelee eletunnistusta Kinect syvyyskameran avulla. 
Työn tarkoitus on tutustua erilaisiin eletunnistusmenetelmiin ja tutkia niitä käytännönsovellusten kuten
elekäyttöliittymien näkökulmasta. Tutkimuksessa kiinnitetäänkin huomioita erityisesti "yhdestä otoksesta oppimiseen" 
ja tranfer-oppimiseen eli perehdytään siihen miten eletunnistusmenetelmät oppivat tunnistamaan liikkeitä mahdollisimman
pienellä määrällä annettua dataa. Tämä on kuluttujaystävällistä, loppukäyttäjät eivät usein halua treenata kameraa tuhansilla toistoilla.\\
One Shot Learning Gesture Recognition with Kinect Sensor, Di Wu, Fan Zhu, Ling Shao
Kuvaa ja videokuvaa on tutkittu paljon mutta eletunnistus on vielä melko uusi haaste. Elentunnistuksen mahdollistavat uudet kehittyneet
sensorit kuten Microsoftin Kinect -sensori ja kehittynyt laskentateho. Lisätäkseen alan kiinnostusta järjestttiin ChaLearn challenge
eletunnistuskilpailu, joissa kilpailijat kehittivät Kinect sensorin datalle suunnattuja eletunnistus menetelmiä. Tämä kandinaatin työ 
tutustuu kilpailutöihin ja kartoittaa niiden avulla alan uusinta tutkimusta.\\
Aaron F. Bobick, Member, IEEE Computer Society, and
James W. Davis, Member, IEEE Computer Society
The Recognition of Human Movement Using Temporal Templates\\
Kinect sensori tarjoaa ns. 3D -videokuvaa eli tavallisen värikuvan lisäksi Kinect -kamera antaa infrapunakameralla mitattua syvyyskuvaa.


\section{Eletunnistus videokuvalta}
\label{Eletunnistus videokuvalta}

Eletunnistusvideokuvalta koostuu seuraavista vaiheista. Kuvaa esikäsitellään, siitä poistetaan esim häiriötä tai Kinectin tapauksessa taustaa.
Kuvasta valitaan piirteet joiden mukaan sitä luokitellaan. Piirrevalintaa voisi tarkoittaa vaikka sitä että jos haluamme luokitella ihmisiä 
valitsemmeko pituuden tai painon tai jonkin täysin muun tekijän kuten laulutaidon. Piirteitä voidaan valita useita
jolloin meillä on moniulottoinen avaruus, jossa pisteitä käsitellään. Tällainen on hankala piirtää 2D -tasoon ja se tekee laskennasta usein raskasta
mutta on välttämätön jotta voidaan erottaa useampia eri luokkia. Jostain tilanteissa piirteiden määrää voidaa vähentää sopivalla lineaarikuvauksella.\\

Videokuvan tapauksessa suoritetaan seuraavaksi ajallinen jako. Videokuva jaetaan siis pätkiin joiden sisällä ei ole liikettä. 
Tyypilliset videopätkät tiivistetään yksittäiseen kuvaan, hävittäen aikaulottovuus. Videokuvan ajallinen jako voidaan suorittaa etukäteen
vertailemalla esimerkiksi vertailemalla peräkkäisten framejen samankaltaisuutta. Esimerkiksi videokuvassa jossa ihminen ensin istuu ja sitten nousee seisomaan
voidaan erottaa ainakin kolme erillistä jaksoa: istuminen, nouseminen ja seisominen. Jako voi tapahtua myös tunnistuksen aikana.\\

Tämän jälkeen pyritään löytämään jokin yhteys piirteiden ja luokan välillä. Ongelmamme on luokitusongelma; tiedämme etukäteen mitä luokkia on olemassa.
Opetusvaiheessa tiedämme luokan voimme johtaa jonkin funktion näytteen ja luokan välille. 
Tutkimus riippuu valitsemistamme piirteistä, joita voisivat olla esimerkiksi: onko kuvassa tapahtunut vaakasuuntaista liikettä? Onko kuvissa havaittavissa paljon pystysuoria viivoja?
Tässä voidaan käyttää erilaisia luokittelualgoritmea lähin naapuri esimerkiksi.\\

Luotuamme funktion ja näytteen välille voimme siirtyä opetusdataan. Opetusdatassa tiedämme oikeat vastaukset, mutta suoritamme laskennat kuin emme tietäisi.
Opetusdataa voidaan käyttää arvoimaan luokittimen kykyä arvioida muuta dataa kuin sitä millä se on luotu.\\

Ihminen on erittäin taitava eletunnistuksessa. Ihminen oppii uuden eleen yhdestä näytteestä. Ihminen tunnistaa liikkeen tai eleen vaikka
kuva oli sumea eikä yksittäisestä framesta erottaisi hahmoa. Eletunnistuksessa ollaan kiinnostuneita ihmisen kyvystä tunnistaa eleitä ja
pyritään matkimaan ihmisen eletunnistus näköä. Kuvista ei esimerkiksi pyritään erottamaan hahmoa vaan ihmisen havaitsemiskyvyn tavoin
tutkitaan pelkkää liikettä.\\




\section{ChaLearn Gesture Challenge -kilpailu}
\label{ChaLearn Gesture Challenge -kilpailu}

\subsection{Kilpailun esittely}
ChaLearn Gesture Challenge kilpailun tarkoituksena oli lisätä kiinnostusta eletunnistukseen syvyyskameroilla.
Kilpailussa jaettiin 50 000 Kinect-sensorilla kuvattua videonäytettä. Videonäytteet sisälsivät esimerkiksi viittomia
tai poliisin käsimerkkejä. Kilpailijoiden tarkoitus oli kehittää eletunnistusmenetelmä jonka avulla eleet opitaan yhdestä opetusnäytteestä.
Eleitä oli jaettu kategorioihin käyttötilanteen mukaan esimerksi poliisin käsimerkit olivat yksi kategoria. Eleet joilla kilpailutöitä
testattiin olivat eri eleitä kuin opetusdatassa mutta samoista kategorioista.\\
Videoklipeillä esiintyi aina yksi ihminen kerrallaan suorittamassa tiettyä elesarjaa. Kuva rajatttiin yläruumiiseen ja eleet tehtiin
pääasiallisesti käsillä. Liikkeet lopetettiin ja aloitettiin aina samasta lepoasennosta. Videonäytteet sisälsivät syvyyskamerakuvan sekä värikuvan 
mutta ei ranganseurausta. Haasteita toivat vaihtelevat taustat ja valaistukset videoilla.\\
Kilpailijoille jaettiin kolme datajoukko: kehitysdata, validointidata ja lopullinen arviointidata. Dataa oli luokiteltu kategorioihin sen mukaan
oliko kyseessä esimerkiksi viittoma, luonnollinen ele vai tanssiasento. Opetusdatassa näytteille annettiin laabelit kuvaamaan oikeaa ratkaisua.
Validointi ja arviointi datassa vain osalla oli oikeat laabelit. Kilpailun loppupuolella paljastettiin lopullinen testidata jonka avulla tuloksia arvioitiin\\

The Recognition of Human Movement Using Temporal Templates
00910878.pdf


\subsection{Katsaus kilpailutöihin}
Kilpailijoiden metodeja selvitettiin lyhyellä kyselyllä, johon vastasi 20 ryhmää 22 parhaan ryhmän joukosta.
Lähes kaikki tiimit tekivät jonkinlaista kuvien esikäsittelyä. Kuvista poistetiin häiriötä, asiaanliittymättömiä kohteita tai tausta.
Huomioitavaa on kuitenkin, että jotkin hyvin menestyneistä ryhmistä eivät tehneet minkäänlaista esikäsittelyä kuville.\\

Suurin osa osallistujista käytti HOG/HOF - piirteitä, SIFT/STIP piirteitä, kulmien tai nurkkien tunnistusta tai kehitti omia tälle datalle soveltuvia ominaisuuksia.
Suurin osa käytti pelkkää syvyyskuvaa, osa molempia, sekä väri että syvyyskuvaa. Toisen sijan voittaja käytti pelkkää RGB-videokuvaa. 
Tyypillisesti kilpailijat käyttivät ominaisuuksien valintaa, tiivistystä tai kuvausta toiseen lineaariavaruuteen.\\

Videokuva jaetaan ajallisesti osioihin perustuen videokuvan samankaltaisuuteen. Tunnistuksessa voidaan käytttää erilaisia graafisia malleja
kuten Hidden Markov Model ja Conditional Random Fields. Itse luokittelu tapahtui KNN tai muilla yksinkertaisilla keinoilla. 
Kilpailun järjestejien odottamaa metodia Transfer learning käytettiin, tosin kukaan menestyneistä kilpailijoista ei käyttänyt sitä.\\

Kilpailutöissä huomattavaa oli että ne käyttivät hyvin erilaista lähestymistapaa. 
Ryhmä xiaozhuwudi käytti työssään MHI-tekniikkaa eli tutkittiin viimeaikaisen liikkeen määrää videokuvassa eri ajan hetkinä.

Ryhmä zunga valitsi piirteiksi horisontaalisen ja vertikaalisen liikkeen seka kuvan ulkoasun. Tämä jälkeen yritetään löytää
regressio eli funktio joka kuvaa piirteet oikeaan luokkaan. Oikea funktio haetaan minimoimalla virheen neliötä.

Ryhmä immortals lähti liikkeelle ajatukseta että liikkeet koostuvat sarjaista yksittäisä eleitä.
Immortals käytti valmista databasea useista liikkeista ja koosti liikkeistä malleja joita se käytti tunnistuksessa.

Ensimmäinen ryhmä näytti keskittyvän piirrevalintaan, toinen ryhmä regressioon ja kolmas ryhmä videokuvan tunnistuspuoleen.

\subsection{xiaozhuwudi ja laajennettu MHI}
Ryhmä xiaozhuwudi lähti liikkeelle MHI eli Motion History Image -tekniikasta. MHI tutkii liikkeen määrää videokuvalla.
Videopätkä tiivistetään yhteen liikekuvaan, joka kuvaa liikkeen viimeaikaisuutta. Kohdat, joissa videokuvalla on ollut
liikettä esitetään harmaasävyillä. Mitä viimeaikasempaa liike on ollut sitä valkoisempana se näkyy kuvassa. Liikkumattomat
alueet näkyvät täysin mustana. Videokuvalta tutkitaan siis vain liikettä, eikä pyritä esimerkiksi tunnistamaan kuvalla olevia kohteita
tai ihmiskehon osia. Tämä menetelmä matkii ihmisen tapaa tunnistaa eleitä. Ihminen tunnistaa erittäin hyvin eleet kuten vilkutuksen 
sumealta videokuvalta vaikka ei yksittäisestä framesta tunnistaisi edes ihmishahmoa.  \\
Xiaozhuwudi-ryhmä tunnistaa MHI:ssa kuitenkin ongelmia. MHI ei tunnista kovin hyvin eleitä jotka sisältävät toistuvia liikkeitä kuten vilkutusta.
Liikkeen toistuessa liikerata vahvistuu MHI-kuvassa, mutta samalla ajallinen tieto katoaa. Esimerkiksi missä käsi oli ensin ja kuinka nopeasti se liikkui.
Xiaozhuwudi ehdottaa MHI:n laajentamista INV ja GEI -kuvilla. INV oon käänteinen kuvaus MHI:ille. INV:ssa katsotaan videokuvaa alusta loppuun päin.
Mitä aikasemmin liike esiintyy videolla sitä vaalempana se näytetään kuvassa. INV:n avulla saadaan kuvaus videon alkutilanteesta jolla voidaan
täydentää MHI kuvaa. GEI kuvaa liikkeen määrää keskimäärin koko videon aikana. Se muistuttaa MEI:tä (Motion Energy Image) eli siinä summataan
koko videon liike. Voidaan ajatella että siinä missä MHI mittaa liikettä MEI ja GEI mittaavat energiaa, joka on kulunut liikkeeseen. GEI:ssä 
lopuksi jaetaan energia koko aikavälille. GEI:n avulla liikkeestä saadaan hyvä kokonaiskuva ja se tukee hyvin etenkin toistuvan liikkeen tunnistuksessa. \\
Datan esikäsittelyssä xiaozhuwudi hyödynsi Kinectin syvyyskuvaa poistamalla taustan ihmishahmolta. Lisäksi esikäsittelyssä poistettiin häiriöitä.
MHI, GEI ja INV -kuville suoritettiin dimensioiden vähennys. Eleiden tunnistukseen käytettiin Maximum Correlation Coeffient -luokittelijaa.
xiaozhuwudi sijoittui kilpailussa kahdeksannelle sijalle.


Aaron F. Bobick, Member, IEEE Computer Society, and
James W. Davis, Member, IEEE Computer Society
The Recognition of Human Movement Using Temporal Templates
00910878.pdf

Silhouette Analysis-Based Action Recognition Via
Exploiting Human Poses
Di Wu, Student Member, IEEE, and Ling Shao, Senior Member, IEEE


\subsection{immortals ja Hidden Markov Model}

Ryhmä immortals käytti erilaista lähestymistapaa. Ryhmä oletti vastoin yleistä tapaa,
että yksittäinen ele koostuu ennen kaikkia useista yksittäisistä liikkeistä. Sen mukaan eleet tunnistetaan parhaiten
käsittelmällä elettä useasta liikkeestä koostuvana yhdistelmänä. Tämä eroaa esimerkiksi ryhmän xiaozhuwudi, joka käsitteli
eleitä kokonaisuuksina.\\
Ryhmä lähti liikkeelle opetusvaiheessa yksittäisistä liikkeistä. Yksittäisille liikkeille luodaan allekirjoitus tai malli,
jonka avulla ne voidaan tunnistaa. Allekirjoituksen luominen on monivaiheinen operaatio. Ensin kuvista poimitaan niin sanotut
tärkeät pisteet eli pisteet joilla on merkitystä liikkeen tunnistamisen kannalta. Tässä Immortals hyödynsi Kinectin syvyyskuvaa.
Immortals arvioi, että ne kohdat kuvasta joissa on tapahtunut muutosta syvyyskameran kuvassa ovat kyseisen videon pysäytyskuvan
tärkeitä pisteitä. Tämän jälkeen tärkeille pisteille lasketaan HOG (Histogram of oriented gradients) ja HOF (Histogram of Flow). 
Kuva jaetaan pieniin alueisiin joille lasketaan gradienttien suuntien histogrammi. Ajatuksen on päätellä minkä suuntaisia 
viivoja alueelta voidaan erottaa. Tämän jälkeen historgrammin ryhmitellään "visuaalisiksi sanoiksi" tavallisen ryhmittelyalgoritmin avulla.
Tarkoituksena on tutkia sanojen esiintymistä yhdessä ja muodostaa niistä "otsikoita". Voidaan siis kuvata yksittäistä pysäytyskuvaa
sillä, mitkä sanat esiintyvät siinä.\\
Tämän luodaan liikkeelle piirteiden perusteella malli jolla se voidaan tunnistaa. Mallin perustana on Markovin piilomalli eli HMM (Hidden Markov Model).
Malli kertoo kuinka todennäköisesti tietty havainto kuuluu luokkaan, jota se kuvaa. Koska tutkitaan kahta ominaisuutta HOG ja HOF,
käytetään monikanavaista Markovin piilomallia eli McHMM. HOG ja HOF paljastavat erilaista tietoa havainnosta ja tukevat tässä hyvin toisiaan.
McHMM parametreja ovat alkutila, todennäköisyys tilojen väliselle muutokselle sekä tilan todennäköisyys ja kuvaaja. Tilalla tarkoitetaan
yksittäistä pysäytyskuvaa. Parametrien arvot optimoidaan niin, että todennököisyys opetusliikkeelle kuulua kuvaamaansa luokkaan on mahdollisimman suuri.

LÄHDE HOGILLE, joku muu kuin wikipedia :)
A Temporal Bayesian Model for Classifying, Detecting and Localizing Activities
in Video Sequences
Manavender R. Malgireddy
University at Buffalo
mrm42@buffalo.edu
Ifeoma Inwogu
University at Buffalo
inwogu@buffalo.edu
Venu Govindaraju
University at Buffalo
govind@buffalo.edu
% --------------------------------------------------------------------

\section{Loppuluku}



% --------------------------------------------------------------------

